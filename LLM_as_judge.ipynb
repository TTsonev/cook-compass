{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c54f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install huggingface_hub pandas ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9de4dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    api_key=os.environ[\"API_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"vegetarian pasta with tomatoes and spinach\"\n",
    "\n",
    "model_response = \"\"\"\n",
    "1. Spinach and Tomato Penne Pasta\n",
    "   Ingredients: penne pasta, fresh spinach, cherry tomatoes, garlic, olive oil, parmesan\n",
    "\n",
    "2. Creamy Chicken and Tomato Pasta\n",
    "   Ingredients: pasta, chicken breast, tomatoes, cream, garlic\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                You are an impartial evaluation model acting as a judge for a recipe\n",
    "                recommendation system called CookCompass.\n",
    "\n",
    "                Your task is to evaluate the SYSTEM RESPONSE based on the USER QUERY\n",
    "                and score it on the criteria listed below.\n",
    "\n",
    "                Do NOT rewrite, improve, or explain the recipe.\n",
    "                Only evaluate it.\n",
    "\n",
    "                --------------------------------------------------\n",
    "                USER QUERY:\n",
    "                {user_query}\n",
    "\n",
    "                --------------------------------------------------\n",
    "                SYSTEM RESPONSE:\n",
    "                {model_response}\n",
    "\n",
    "                --------------------------------------------------\n",
    "                EVALUATION CRITERIA:\n",
    "\n",
    "                1. RELEVANCE (0-10):\n",
    "                How well does the response satisfy the user's query and constraints?\n",
    "                Consider:\n",
    "                - Correct handling of dietary restrictions (e.g. vegetarian, allergies)\n",
    "                - Use of requested ingredients\n",
    "                - Avoidance of forbidden ingredients\n",
    "                - Overall alignment with the intent of the query\n",
    "\n",
    "                Score meaning:\n",
    "                0 = Completely irrelevant or violates key constraints  \n",
    "                5 = Partially relevant, but with notable issues  \n",
    "                10 = Fully relevant and perfectly aligned with the query  \n",
    "\n",
    "                2. HEALTHINESS (0-10):\n",
    "                How healthy are the suggested recipe(s) in a general nutritional sense?\n",
    "                Consider:\n",
    "                - Balance of ingredients (e.g. vegetables, fats, protein)\n",
    "                - Excessive use of sugar, salt, or ultra-processed ingredients\n",
    "                - Suitability for everyday consumption (not medical advice)\n",
    "\n",
    "                Score meaning:\n",
    "                0 = Extremely unhealthy  \n",
    "                5 = Moderately healthy  \n",
    "                10 = Very healthy and well-balanced  \n",
    "\n",
    "                3. TASTE (0-10):\n",
    "                How appealing and plausible are the recipe(s) from a culinary perspective?\n",
    "                Consider:\n",
    "                - Ingredient compatibility\n",
    "                - Flavor balance\n",
    "                - Whether the recipe makes sense to a typical cook\n",
    "\n",
    "                Score meaning:\n",
    "                0 = Unappetizing or nonsensical  \n",
    "                5 = Acceptable but unexciting  \n",
    "                10 = Highly appealing and well-composed  \n",
    "\n",
    "                --------------------------------------------------\n",
    "                OUTPUT FORMAT (STRICT JSON):\n",
    "\n",
    "                {{\n",
    "                \"relevance\": <integer 0-10>,\n",
    "                \"healthiness\": <integer 0-10>,\n",
    "                \"taste\": <integer 0-10>\n",
    "                }}\n",
    "                \"\"\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "res = completion.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9aca4bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"relevance\": 3,\\n  \"healthiness\": 8,\\n  \"taste\": 7\\n}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a588ac1",
   "metadata": {},
   "source": [
    "1. create prompt\n",
    "2. find another model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
